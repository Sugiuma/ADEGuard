{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"7287153885b444bc89f9f30d74539cf2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a4eaca8dd46346c285d7b96795915048","IPY_MODEL_eab1feeb64ce4a039c524cadbfb99e17","IPY_MODEL_3353c39d481e4d698b4f150702f441c9"],"layout":"IPY_MODEL_4effa31b7e634fac81a02688a553ace9"}},"a4eaca8dd46346c285d7b96795915048":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0d347ab21314aa1989a84cde61172c5","placeholder":"​","style":"IPY_MODEL_f5679f80c4fe41d79dd0db6c1483df55","value":"config.json: 100%"}},"eab1feeb64ce4a039c524cadbfb99e17":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d198d1765f54b338f7a030e5e669aa7","max":313,"min":0,"orientation":"horizontal","style":"IPY_MODEL_63c03b8a1aba4a2a8bfa42ddbf8d2a0d","value":313}},"3353c39d481e4d698b4f150702f441c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_473f973e92214a3491edfbce51270ba9","placeholder":"​","style":"IPY_MODEL_0ae24d75d6e64868bbfd127afb176dd7","value":" 313/313 [00:00&lt;00:00, 27.7kB/s]"}},"4effa31b7e634fac81a02688a553ace9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0d347ab21314aa1989a84cde61172c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5679f80c4fe41d79dd0db6c1483df55":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d198d1765f54b338f7a030e5e669aa7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63c03b8a1aba4a2a8bfa42ddbf8d2a0d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"473f973e92214a3491edfbce51270ba9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ae24d75d6e64868bbfd127afb176dd7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ff50ee8b550b4550b9912417dfd61465":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e52789ebb04f4f2f837f538ec6fc9b9d","IPY_MODEL_5b0332f41eac4b0c9e56bb547c6f65cd","IPY_MODEL_5cb6f2b21fa6452186d604cfd2eca80b"],"layout":"IPY_MODEL_2dc793daea5b4782a1ff7ae84164d1da"}},"e52789ebb04f4f2f837f538ec6fc9b9d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_335806384b744695a315af1b35fcf93c","placeholder":"​","style":"IPY_MODEL_3096f0e7dd154f78904dce38ec66749d","value":"vocab.txt: "}},"5b0332f41eac4b0c9e56bb547c6f65cd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6486ce1031841cdb6323c40ef22dd1e","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b9481b037c4144e99c7ec65c8886f291","value":1}},"5cb6f2b21fa6452186d604cfd2eca80b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2d169102042457b943bc594218ff4cb","placeholder":"​","style":"IPY_MODEL_5c66da4487e2458eaebccb8b59d9687f","value":" 213k/? [00:00&lt;00:00, 8.38MB/s]"}},"2dc793daea5b4782a1ff7ae84164d1da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"335806384b744695a315af1b35fcf93c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3096f0e7dd154f78904dce38ec66749d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6486ce1031841cdb6323c40ef22dd1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"b9481b037c4144e99c7ec65c8886f291":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e2d169102042457b943bc594218ff4cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c66da4487e2458eaebccb8b59d9687f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c0690b03b78412c86fcf1ecb7d0c18e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_31aca0d35c61447687e6d5f5037f8a94","IPY_MODEL_d5a41b4e38854baf8e5c3d58bee06e68","IPY_MODEL_288c12cb6ca54ac0b20ca255d78ea493"],"layout":"IPY_MODEL_bedb6ca393f74877b5befe0462545a83"}},"31aca0d35c61447687e6d5f5037f8a94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3a68166024e489382d6465330316c2f","placeholder":"​","style":"IPY_MODEL_afbd9917a29247b2b5681793be6c9dda","value":"pytorch_model.bin: 100%"}},"d5a41b4e38854baf8e5c3d58bee06e68":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e83d08cc086e48668ce2abaa75f7f5af","max":435780550,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6eff9a6371904e38a21bf6d5050b49b2","value":435780550}},"288c12cb6ca54ac0b20ca255d78ea493":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bf4733e0f7342458462e91bf9122e1e","placeholder":"​","style":"IPY_MODEL_6df9abc943b34bbb85bdac01db4c0b6e","value":" 436M/436M [00:06&lt;00:00, 58.9MB/s]"}},"bedb6ca393f74877b5befe0462545a83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3a68166024e489382d6465330316c2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afbd9917a29247b2b5681793be6c9dda":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e83d08cc086e48668ce2abaa75f7f5af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6eff9a6371904e38a21bf6d5050b49b2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5bf4733e0f7342458462e91bf9122e1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6df9abc943b34bbb85bdac01db4c0b6e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e32cd478b72446b791a41d06c09a2105":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0ff6b890d78c41c08d231e210fbeaa15","IPY_MODEL_134ed6c96ebb4bbc9deac279faa4991f","IPY_MODEL_a52387b1d2114d45a0aec890df26cde0"],"layout":"IPY_MODEL_812c7ca0c67b46a7a0484cb75bf70774"}},"0ff6b890d78c41c08d231e210fbeaa15":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d926ebbd216a473698060b5f6a91ea86","placeholder":"​","style":"IPY_MODEL_ad54e7d4b18e4f938322c13dd3e0d350","value":"Map: 100%"}},"134ed6c96ebb4bbc9deac279faa4991f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e29b30e3cf9946c683ee961db859a731","max":15661,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5844e0a0f666485584ad3cb99ad6e8a6","value":15661}},"a52387b1d2114d45a0aec890df26cde0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec1d9d9d3e8c4df4afbac41323f787fa","placeholder":"​","style":"IPY_MODEL_615103d1e3fc4be6bbb2ce8697e82a40","value":" 15661/15661 [00:19&lt;00:00, 676.00 examples/s]"}},"812c7ca0c67b46a7a0484cb75bf70774":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d926ebbd216a473698060b5f6a91ea86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad54e7d4b18e4f938322c13dd3e0d350":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e29b30e3cf9946c683ee961db859a731":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5844e0a0f666485584ad3cb99ad6e8a6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ec1d9d9d3e8c4df4afbac41323f787fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"615103d1e3fc4be6bbb2ce8697e82a40":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3904858982a94fe798dd720c2e9e0a20":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_42686ecab825463dae04139c108064cd","IPY_MODEL_9484713ca5ec476d9d0d05374bc1bafb","IPY_MODEL_4f74d851b3a64f0d83f0205fc1eb2239"],"layout":"IPY_MODEL_52b1f441384d45ec92148d590ca7cf03"}},"42686ecab825463dae04139c108064cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6ff5b88318e4a6190b0cac538716429","placeholder":"​","style":"IPY_MODEL_4fcd9045e2fe4ce79006bf67df7612a2","value":"Map: 100%"}},"9484713ca5ec476d9d0d05374bc1bafb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_630702ae8d01462086249350ddc7e91e","max":1382,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d5e4ec0c3eaa4fa3b82cc2afcd579cf1","value":1382}},"4f74d851b3a64f0d83f0205fc1eb2239":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13dece3ca1c945d3be9ad4ebd83e2ed8","placeholder":"​","style":"IPY_MODEL_0ae469b66a8842b68b549ba2d0d103d4","value":" 1382/1382 [00:02&lt;00:00, 647.35 examples/s]"}},"52b1f441384d45ec92148d590ca7cf03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6ff5b88318e4a6190b0cac538716429":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fcd9045e2fe4ce79006bf67df7612a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"630702ae8d01462086249350ddc7e91e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5e4ec0c3eaa4fa3b82cc2afcd579cf1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"13dece3ca1c945d3be9ad4ebd83e2ed8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ae469b66a8842b68b549ba2d0d103d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ae989c82ddb4bb4b2638c423500e33d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_09a33a8ccb984c71ae85160d29cfa810","IPY_MODEL_0b9d3f4782704df0815b8643cd35114a","IPY_MODEL_27769f6985784f99a2c87b15d9530c19"],"layout":"IPY_MODEL_7eef2d8251674f3e9552d4924551e83d"}},"09a33a8ccb984c71ae85160d29cfa810":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6741dcdb0b284034a75a703378153f7e","placeholder":"​","style":"IPY_MODEL_8b72d170983b4caebce92ba8fa55479a","value":"Map: 100%"}},"0b9d3f4782704df0815b8643cd35114a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_20bc7f3dd77e41cb81c736d508847b74","max":1382,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ba8db41ca41b407186229efc07b55f45","value":1382}},"27769f6985784f99a2c87b15d9530c19":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c484130ea31849da9dcabebe9a66e9a0","placeholder":"​","style":"IPY_MODEL_7dd3eca76a984e009ef9bf64b107d343","value":" 1382/1382 [00:01&lt;00:00, 759.83 examples/s]"}},"7eef2d8251674f3e9552d4924551e83d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6741dcdb0b284034a75a703378153f7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b72d170983b4caebce92ba8fa55479a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20bc7f3dd77e41cb81c736d508847b74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba8db41ca41b407186229efc07b55f45":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c484130ea31849da9dcabebe9a66e9a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7dd3eca76a984e009ef9bf64b107d343":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install transformers datasets seqeval evaluate\n","\n","from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification\n","from datasets import Dataset, DatasetDict\n","import numpy as np\n","from seqeval.metrics import precision_score, recall_score, f1_score, accuracy_score\n","import random\n","from sklearn.model_selection import train_test_split"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IYj1HZ1j7ZuA","executionInfo":{"status":"ok","timestamp":1759512618314,"user_tz":240,"elapsed":46865,"user":{"displayName":"Sugi g","userId":"15669796817362053311"}},"outputId":"ec7f40e2-045d-49b9-bf9d-daaaa53f3388","collapsed":true},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.2)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting evaluate\n","  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from seqeval) (1.6.1)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.16.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=c625ac50c0f53027bee628661d301288d3a3caeaf96f33f59fd7e84ac8ad3f86\n","  Stored in directory: /root/.cache/pip/wheels/5f/b8/73/0b2c1a76b701a677653dd79ece07cfabd7457989dbfbdcd8d7\n","Successfully built seqeval\n","Installing collected packages: seqeval, evaluate\n","Successfully installed evaluate-0.4.6 seqeval-1.2.2\n"]}]},{"cell_type":"code","source":["# -------------------------------\n","# STEP 1: Detect labels from files\n","# -------------------------------\n","def collect_labels(files):\n","    labels = set()\n","    for file in files:\n","        with open(file, \"r\", encoding=\"utf-8\") as f:\n","            for line in f:\n","                line = line.strip()\n","                if not line:\n","                    continue\n","                parts = line.split()\n","                labels.add(parts[-1])  # last col = label\n","    return sorted(list(labels))\n","\n","label_list = collect_labels([\"/content/sample_data/project1.conll\"])#, \"/content/sample_data/gold.conll\"])\n","label2id = {label: i for i, label in enumerate(label_list)}\n","id2label = {i: label for i, label in enumerate(label_list)}\n","print(\"Detected labels:\", label_list)\n","\n","# -------------------------------\n","# STEP 2: Reader for your format\n","# -------------------------------\n","def read_conll(filepath):\n","    examples = []\n","    tokens, tags = [], []\n","\n","    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n","        for line in f:\n","            line = line.strip()\n","            if not line:\n","                if tokens:\n","                    examples.append({\"tokens\": tokens, \"ner_tags\": [label2id[tag] for tag in tags]})\n","                    tokens, tags = [], []\n","                continue\n","\n","            parts = line.split()\n","            token, tag = parts[0], parts[-1]   # first col = token, last col = label\n","            tokens.append(token)\n","            tags.append(tag)\n","\n","        if tokens:  # last sentence\n","            examples.append({\"tokens\": tokens, \"ner_tags\": [label2id[tag] for tag in tags]})\n","\n","    return examples\n","\n","# -------------------------------\n","# STEP 3: Build dataset\n","# -------------------------------\n","silver_data = read_conll(\"/content/sample_data/project1.conll\")   # weak silver labels\n","#gold_data   = read_conll(\"/content/sample_data/gold.conll\")     # gold labels\n","\n","#print(\"Gold examples:\", len(gold_data))\n","print(\"Silver examples:\", len(silver_data))\n","\n","random.shuffle(silver_data)\n","#random.shuffle(gold_data)\n","\n","# assume you already have silver_data = list of samples (~9000+)\n","\n","# First split: train vs temp (val+test)\n","train_data, temp_data = train_test_split(\n","    silver_data,\n","    test_size=0.15,   # 15% goes to val+test\n","    random_state=42,  # reproducibility\n","    shuffle=True\n",")\n","\n","# Second split: val vs test\n","val_data, test_data = train_test_split(\n","    temp_data,\n","    test_size=0.5,    # half of 15% → 7.5% test, 7.5% val\n","    random_state=42,\n","    shuffle=True\n",")\n","\n","print(f\"Train: {len(train_data)}\")\n","print(f\"Val:   {len(val_data)}\")\n","print(f\"Test:  {len(test_data)}\")\n","\n","\n","#train_data = silver_data + gold_data[:350]  # mix weak + gold\n","#val_data   = gold_data[350:425]  # ~75 examples\n","#test_data  = gold_data[425:]     # ~75 examples\n","\n","dataset = DatasetDict({\n","   \"train\": Dataset.from_list(train_data),\n","   \"validation\": Dataset.from_list(val_data),\n","    \"test\": Dataset.from_list(test_data),\n","})\n","\n","#print(dataset)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m0uciJsK7nxz","executionInfo":{"status":"ok","timestamp":1759512631120,"user_tz":240,"elapsed":7269,"user":{"displayName":"Sugi g","userId":"15669796817362053311"}},"outputId":"fce5bde6-2ae3-4ff9-eb3e-a98c67b6a2a3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Detected labels: ['B-ADE', 'B-DRUG', 'I-ADE', 'I-DRUG', 'O']\n","Silver examples: 18425\n","Train: 15661\n","Val:   1382\n","Test:  1382\n"]}]},{"cell_type":"code","source":["from collections import Counter\n","\n","def print_label_counts(dataset, split_name, key=\"ner_tags\"):\n","    \"\"\"\n","    Print label counts for a dataset split.\n","    - dataset: HuggingFace Dataset\n","    - split_name: \"train\", \"validation\", or \"test\"\n","    - key: column containing labels (\"ner_tags\" before tokenization, \"labels\" after)\n","    \"\"\"\n","    counts = Counter()\n","    for labels in dataset[split_name][key]:\n","        counts.update(labels)\n","\n","    # remove padding ignore index (-100) if present\n","    if -100 in counts:\n","        del counts[-100]\n","\n","    print(f\"\\n🔹 {split_name} counts (from '{key}'):\")\n","    for label_id, cnt in sorted(counts.items()):\n","        print(f\"  {label_id:>2} : {cnt}\")\n"],"metadata":{"id":"coipJ3HX1vDK","executionInfo":{"status":"ok","timestamp":1759512659061,"user_tz":240,"elapsed":25,"user":{"displayName":"Sugi g","userId":"15669796817362053311"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from datasets import Dataset, DatasetDict\n","from collections import Counter\n","import torch\n","import torch.nn as nn\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForTokenClassification,\n","    TrainingArguments,\n","    Trainer\n",")\n","import evaluate\n","import numpy as np"],"metadata":{"id":"yXFD9sOxml8e","executionInfo":{"status":"ok","timestamp":1759512664898,"user_tz":240,"elapsed":1189,"user":{"displayName":"Sugi g","userId":"15669796817362053311"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# -----------------------------\n","# 3️⃣ Load your dataset\n","# -----------------------------\n","dataset = DatasetDict({\n","    \"train\": Dataset.from_list(train_data),\n","    \"validation\": Dataset.from_list(val_data),\n","    \"test\": Dataset.from_list(test_data),\n","})\n","\n","label_column = \"ner_tags\"\n","\n","# Original 5-label scheme\n","#orig_label_list = [\"O\", \"B-ADE\", \"I-ADE\", \"B-DRUG\", \"I-DRUG\"]"],"metadata":{"id":"4io2J-ELmqAN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for split in [\"train\", \"validation\", \"test\"]:\n","    print_label_counts(dataset, split, key=\"ner_tags\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rqFfUzwj1zoG","executionInfo":{"status":"ok","timestamp":1759512670317,"user_tz":240,"elapsed":2757,"user":{"displayName":"Sugi g","userId":"15669796817362053311"}},"outputId":"a03a1a39-fa18-40f7-edc2-6ee553b6909a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","🔹 train counts (from 'ner_tags'):\n","   0 : 160609\n","   1 : 19189\n","   2 : 87646\n","   3 : 8335\n","   4 : 1851776\n","\n","🔹 validation counts (from 'ner_tags'):\n","   0 : 5540\n","   1 : 1639\n","   2 : 1269\n","   3 : 679\n","   4 : 167814\n","\n","🔹 test counts (from 'ner_tags'):\n","   0 : 5586\n","   1 : 1602\n","   2 : 1195\n","   3 : 660\n","   4 : 158591\n"]}]},{"cell_type":"code","source":["import torch\n","from transformers import BertTokenizerFast, BertForTokenClassification, Trainer, TrainingArguments\n","from collections import Counter\n","\n","# ------------------------\n","# 1. Define labels\n","# ------------------------\n","label_list = [\"B-ADE\", \"B-DRUG\",\"I-ADE\",\"I-DRUG\",\"O\"]\n","num_labels = len(label_list)\n","label2id = {l: i for i, l in enumerate(label_list)}\n","id2label = {i: l for i, l in enumerate(label_list)}\n","\n","# ------------------------\n","# 2. Compute class weights from dataset\n","# ------------------------\n","def compute_class_weights(dataset, label_column=\"ner_tags\"):\n","    counts = Counter()\n","    for split in [\"train\"]:\n","        for seq in dataset[split][label_column]:\n","            counts.update(seq)\n","    total = sum(counts.values())\n","    weights = []\n","    for i in range(num_labels):\n","        # weight = total / (num_labels * class_count)\n","        weights.append(total / (num_labels * counts[i]) if counts[i] > 0 else 1.0)\n","    return torch.tensor(weights, dtype=torch.float)\n","\n","class_weights = compute_class_weights(dataset)\n","print(\"Class weights:\", class_weights)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6KxBsmAnV5OP","executionInfo":{"status":"ok","timestamp":1759512713576,"user_tz":240,"elapsed":1297,"user":{"displayName":"Sugi g","userId":"15669796817362053311"}},"outputId":"cd064b0b-5e40-4e52-dced-c49b05707588"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Class weights: tensor([ 2.6494, 22.1747,  4.8549, 51.0511,  0.2298])\n"]}]},{"cell_type":"code","source":["weights = torch.tensor([ 2.6494, 22.1747,  4.8549, 51.0511,  0.2298])\n","weights = weights / weights.max()  # normalize so max = 1\n","print(\"weights\",weights)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6KlUlWI_Wb6s","executionInfo":{"status":"ok","timestamp":1759512778916,"user_tz":240,"elapsed":20,"user":{"displayName":"Sugi g","userId":"15669796817362053311"}},"outputId":"63729876-7060-4a98-c263-fc68556a6223"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["weights tensor([0.0519, 0.4344, 0.0951, 1.0000, 0.0045])\n"]}]},{"cell_type":"code","source":["print(\"I-DRUG / O weight ratio:\", weights[3]/weights[4])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ihoXTfiNW3ZL","executionInfo":{"status":"ok","timestamp":1759512813165,"user_tz":240,"elapsed":13,"user":{"displayName":"Sugi g","userId":"15669796817362053311"}},"outputId":"cf296dbb-bc2f-45fc-a706-0866f3e27c2f"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["I-DRUG / O weight ratio: tensor(222.1545)\n"]}]},{"cell_type":"code","source":["model_name = \"dmis-lab/biobert-base-cased-v1.1\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","num_labels = len(label_list)  # e.g., 5 labels\n","model = AutoModelForTokenClassification.from_pretrained(\n","    model_name,\n","    num_labels=num_labels,\n","    id2label=id2label,\n","    label2id=label2id,\n","    return_dict=True  # ensures outputs.logits exists\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":168,"referenced_widgets":["7287153885b444bc89f9f30d74539cf2","a4eaca8dd46346c285d7b96795915048","eab1feeb64ce4a039c524cadbfb99e17","3353c39d481e4d698b4f150702f441c9","4effa31b7e634fac81a02688a553ace9","f0d347ab21314aa1989a84cde61172c5","f5679f80c4fe41d79dd0db6c1483df55","5d198d1765f54b338f7a030e5e669aa7","63c03b8a1aba4a2a8bfa42ddbf8d2a0d","473f973e92214a3491edfbce51270ba9","0ae24d75d6e64868bbfd127afb176dd7","ff50ee8b550b4550b9912417dfd61465","e52789ebb04f4f2f837f538ec6fc9b9d","5b0332f41eac4b0c9e56bb547c6f65cd","5cb6f2b21fa6452186d604cfd2eca80b","2dc793daea5b4782a1ff7ae84164d1da","335806384b744695a315af1b35fcf93c","3096f0e7dd154f78904dce38ec66749d","c6486ce1031841cdb6323c40ef22dd1e","b9481b037c4144e99c7ec65c8886f291","e2d169102042457b943bc594218ff4cb","5c66da4487e2458eaebccb8b59d9687f","6c0690b03b78412c86fcf1ecb7d0c18e","31aca0d35c61447687e6d5f5037f8a94","d5a41b4e38854baf8e5c3d58bee06e68","288c12cb6ca54ac0b20ca255d78ea493","bedb6ca393f74877b5befe0462545a83","e3a68166024e489382d6465330316c2f","afbd9917a29247b2b5681793be6c9dda","e83d08cc086e48668ce2abaa75f7f5af","6eff9a6371904e38a21bf6d5050b49b2","5bf4733e0f7342458462e91bf9122e1e","6df9abc943b34bbb85bdac01db4c0b6e"]},"id":"yO7i1B7RbZOe","executionInfo":{"status":"ok","timestamp":1759512830083,"user_tz":240,"elapsed":9337,"user":{"displayName":"Sugi g","userId":"15669796817362053311"}},"outputId":"6a5cf97c-de7b-4f5c-afc7-8d0b1228e821"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/313 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7287153885b444bc89f9f30d74539cf2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff50ee8b550b4550b9912417dfd61465"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c0690b03b78412c86fcf1ecb7d0c18e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["# Freeze all parameters\n","for param in model.bert.parameters():\n","    param.requires_grad = False\n","\n","# Unfreeze the last 4 encoder layers\n","for layer in model.bert.encoder.layer[-4:]:\n","    for param in layer.parameters():\n","        param.requires_grad = True\n","\n","# Classifier head is always trainable\n","for param in model.classifier.parameters():\n","    param.requires_grad = True\n","\n","\n","for name, param in model.named_parameters():\n","    print(name, param.requires_grad)"],"metadata":{"id":"-iJJm9oCbbUK","executionInfo":{"status":"ok","timestamp":1759512833000,"user_tz":240,"elapsed":58,"user":{"displayName":"Sugi g","userId":"15669796817362053311"}},"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"outputId":"c4e5ba5d-8db1-489c-db9d-20d2e28510a1"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["bert.embeddings.word_embeddings.weight False\n","bert.embeddings.position_embeddings.weight False\n","bert.embeddings.token_type_embeddings.weight False\n","bert.embeddings.LayerNorm.weight False\n","bert.embeddings.LayerNorm.bias False\n","bert.encoder.layer.0.attention.self.query.weight False\n","bert.encoder.layer.0.attention.self.query.bias False\n","bert.encoder.layer.0.attention.self.key.weight False\n","bert.encoder.layer.0.attention.self.key.bias False\n","bert.encoder.layer.0.attention.self.value.weight False\n","bert.encoder.layer.0.attention.self.value.bias False\n","bert.encoder.layer.0.attention.output.dense.weight False\n","bert.encoder.layer.0.attention.output.dense.bias False\n","bert.encoder.layer.0.attention.output.LayerNorm.weight False\n","bert.encoder.layer.0.attention.output.LayerNorm.bias False\n","bert.encoder.layer.0.intermediate.dense.weight False\n","bert.encoder.layer.0.intermediate.dense.bias False\n","bert.encoder.layer.0.output.dense.weight False\n","bert.encoder.layer.0.output.dense.bias False\n","bert.encoder.layer.0.output.LayerNorm.weight False\n","bert.encoder.layer.0.output.LayerNorm.bias False\n","bert.encoder.layer.1.attention.self.query.weight False\n","bert.encoder.layer.1.attention.self.query.bias False\n","bert.encoder.layer.1.attention.self.key.weight False\n","bert.encoder.layer.1.attention.self.key.bias False\n","bert.encoder.layer.1.attention.self.value.weight False\n","bert.encoder.layer.1.attention.self.value.bias False\n","bert.encoder.layer.1.attention.output.dense.weight False\n","bert.encoder.layer.1.attention.output.dense.bias False\n","bert.encoder.layer.1.attention.output.LayerNorm.weight False\n","bert.encoder.layer.1.attention.output.LayerNorm.bias False\n","bert.encoder.layer.1.intermediate.dense.weight False\n","bert.encoder.layer.1.intermediate.dense.bias False\n","bert.encoder.layer.1.output.dense.weight False\n","bert.encoder.layer.1.output.dense.bias False\n","bert.encoder.layer.1.output.LayerNorm.weight False\n","bert.encoder.layer.1.output.LayerNorm.bias False\n","bert.encoder.layer.2.attention.self.query.weight False\n","bert.encoder.layer.2.attention.self.query.bias False\n","bert.encoder.layer.2.attention.self.key.weight False\n","bert.encoder.layer.2.attention.self.key.bias False\n","bert.encoder.layer.2.attention.self.value.weight False\n","bert.encoder.layer.2.attention.self.value.bias False\n","bert.encoder.layer.2.attention.output.dense.weight False\n","bert.encoder.layer.2.attention.output.dense.bias False\n","bert.encoder.layer.2.attention.output.LayerNorm.weight False\n","bert.encoder.layer.2.attention.output.LayerNorm.bias False\n","bert.encoder.layer.2.intermediate.dense.weight False\n","bert.encoder.layer.2.intermediate.dense.bias False\n","bert.encoder.layer.2.output.dense.weight False\n","bert.encoder.layer.2.output.dense.bias False\n","bert.encoder.layer.2.output.LayerNorm.weight False\n","bert.encoder.layer.2.output.LayerNorm.bias False\n","bert.encoder.layer.3.attention.self.query.weight False\n","bert.encoder.layer.3.attention.self.query.bias False\n","bert.encoder.layer.3.attention.self.key.weight False\n","bert.encoder.layer.3.attention.self.key.bias False\n","bert.encoder.layer.3.attention.self.value.weight False\n","bert.encoder.layer.3.attention.self.value.bias False\n","bert.encoder.layer.3.attention.output.dense.weight False\n","bert.encoder.layer.3.attention.output.dense.bias False\n","bert.encoder.layer.3.attention.output.LayerNorm.weight False\n","bert.encoder.layer.3.attention.output.LayerNorm.bias False\n","bert.encoder.layer.3.intermediate.dense.weight False\n","bert.encoder.layer.3.intermediate.dense.bias False\n","bert.encoder.layer.3.output.dense.weight False\n","bert.encoder.layer.3.output.dense.bias False\n","bert.encoder.layer.3.output.LayerNorm.weight False\n","bert.encoder.layer.3.output.LayerNorm.bias False\n","bert.encoder.layer.4.attention.self.query.weight False\n","bert.encoder.layer.4.attention.self.query.bias False\n","bert.encoder.layer.4.attention.self.key.weight False\n","bert.encoder.layer.4.attention.self.key.bias False\n","bert.encoder.layer.4.attention.self.value.weight False\n","bert.encoder.layer.4.attention.self.value.bias False\n","bert.encoder.layer.4.attention.output.dense.weight False\n","bert.encoder.layer.4.attention.output.dense.bias False\n","bert.encoder.layer.4.attention.output.LayerNorm.weight False\n","bert.encoder.layer.4.attention.output.LayerNorm.bias False\n","bert.encoder.layer.4.intermediate.dense.weight False\n","bert.encoder.layer.4.intermediate.dense.bias False\n","bert.encoder.layer.4.output.dense.weight False\n","bert.encoder.layer.4.output.dense.bias False\n","bert.encoder.layer.4.output.LayerNorm.weight False\n","bert.encoder.layer.4.output.LayerNorm.bias False\n","bert.encoder.layer.5.attention.self.query.weight False\n","bert.encoder.layer.5.attention.self.query.bias False\n","bert.encoder.layer.5.attention.self.key.weight False\n","bert.encoder.layer.5.attention.self.key.bias False\n","bert.encoder.layer.5.attention.self.value.weight False\n","bert.encoder.layer.5.attention.self.value.bias False\n","bert.encoder.layer.5.attention.output.dense.weight False\n","bert.encoder.layer.5.attention.output.dense.bias False\n","bert.encoder.layer.5.attention.output.LayerNorm.weight False\n","bert.encoder.layer.5.attention.output.LayerNorm.bias False\n","bert.encoder.layer.5.intermediate.dense.weight False\n","bert.encoder.layer.5.intermediate.dense.bias False\n","bert.encoder.layer.5.output.dense.weight False\n","bert.encoder.layer.5.output.dense.bias False\n","bert.encoder.layer.5.output.LayerNorm.weight False\n","bert.encoder.layer.5.output.LayerNorm.bias False\n","bert.encoder.layer.6.attention.self.query.weight False\n","bert.encoder.layer.6.attention.self.query.bias False\n","bert.encoder.layer.6.attention.self.key.weight False\n","bert.encoder.layer.6.attention.self.key.bias False\n","bert.encoder.layer.6.attention.self.value.weight False\n","bert.encoder.layer.6.attention.self.value.bias False\n","bert.encoder.layer.6.attention.output.dense.weight False\n","bert.encoder.layer.6.attention.output.dense.bias False\n","bert.encoder.layer.6.attention.output.LayerNorm.weight False\n","bert.encoder.layer.6.attention.output.LayerNorm.bias False\n","bert.encoder.layer.6.intermediate.dense.weight False\n","bert.encoder.layer.6.intermediate.dense.bias False\n","bert.encoder.layer.6.output.dense.weight False\n","bert.encoder.layer.6.output.dense.bias False\n","bert.encoder.layer.6.output.LayerNorm.weight False\n","bert.encoder.layer.6.output.LayerNorm.bias False\n","bert.encoder.layer.7.attention.self.query.weight False\n","bert.encoder.layer.7.attention.self.query.bias False\n","bert.encoder.layer.7.attention.self.key.weight False\n","bert.encoder.layer.7.attention.self.key.bias False\n","bert.encoder.layer.7.attention.self.value.weight False\n","bert.encoder.layer.7.attention.self.value.bias False\n","bert.encoder.layer.7.attention.output.dense.weight False\n","bert.encoder.layer.7.attention.output.dense.bias False\n","bert.encoder.layer.7.attention.output.LayerNorm.weight False\n","bert.encoder.layer.7.attention.output.LayerNorm.bias False\n","bert.encoder.layer.7.intermediate.dense.weight False\n","bert.encoder.layer.7.intermediate.dense.bias False\n","bert.encoder.layer.7.output.dense.weight False\n","bert.encoder.layer.7.output.dense.bias False\n","bert.encoder.layer.7.output.LayerNorm.weight False\n","bert.encoder.layer.7.output.LayerNorm.bias False\n","bert.encoder.layer.8.attention.self.query.weight True\n","bert.encoder.layer.8.attention.self.query.bias True\n","bert.encoder.layer.8.attention.self.key.weight True\n","bert.encoder.layer.8.attention.self.key.bias True\n","bert.encoder.layer.8.attention.self.value.weight True\n","bert.encoder.layer.8.attention.self.value.bias True\n","bert.encoder.layer.8.attention.output.dense.weight True\n","bert.encoder.layer.8.attention.output.dense.bias True\n","bert.encoder.layer.8.attention.output.LayerNorm.weight True\n","bert.encoder.layer.8.attention.output.LayerNorm.bias True\n","bert.encoder.layer.8.intermediate.dense.weight True\n","bert.encoder.layer.8.intermediate.dense.bias True\n","bert.encoder.layer.8.output.dense.weight True\n","bert.encoder.layer.8.output.dense.bias True\n","bert.encoder.layer.8.output.LayerNorm.weight True\n","bert.encoder.layer.8.output.LayerNorm.bias True\n","bert.encoder.layer.9.attention.self.query.weight True\n","bert.encoder.layer.9.attention.self.query.bias True\n","bert.encoder.layer.9.attention.self.key.weight True\n","bert.encoder.layer.9.attention.self.key.bias True\n","bert.encoder.layer.9.attention.self.value.weight True\n","bert.encoder.layer.9.attention.self.value.bias True\n","bert.encoder.layer.9.attention.output.dense.weight True\n","bert.encoder.layer.9.attention.output.dense.bias True\n","bert.encoder.layer.9.attention.output.LayerNorm.weight True\n","bert.encoder.layer.9.attention.output.LayerNorm.bias True\n","bert.encoder.layer.9.intermediate.dense.weight True\n","bert.encoder.layer.9.intermediate.dense.bias True\n","bert.encoder.layer.9.output.dense.weight True\n","bert.encoder.layer.9.output.dense.bias True\n","bert.encoder.layer.9.output.LayerNorm.weight True\n","bert.encoder.layer.9.output.LayerNorm.bias True\n","bert.encoder.layer.10.attention.self.query.weight True\n","bert.encoder.layer.10.attention.self.query.bias True\n","bert.encoder.layer.10.attention.self.key.weight True\n","bert.encoder.layer.10.attention.self.key.bias True\n","bert.encoder.layer.10.attention.self.value.weight True\n","bert.encoder.layer.10.attention.self.value.bias True\n","bert.encoder.layer.10.attention.output.dense.weight True\n","bert.encoder.layer.10.attention.output.dense.bias True\n","bert.encoder.layer.10.attention.output.LayerNorm.weight True\n","bert.encoder.layer.10.attention.output.LayerNorm.bias True\n","bert.encoder.layer.10.intermediate.dense.weight True\n","bert.encoder.layer.10.intermediate.dense.bias True\n","bert.encoder.layer.10.output.dense.weight True\n","bert.encoder.layer.10.output.dense.bias True\n","bert.encoder.layer.10.output.LayerNorm.weight True\n","bert.encoder.layer.10.output.LayerNorm.bias True\n","bert.encoder.layer.11.attention.self.query.weight True\n","bert.encoder.layer.11.attention.self.query.bias True\n","bert.encoder.layer.11.attention.self.key.weight True\n","bert.encoder.layer.11.attention.self.key.bias True\n","bert.encoder.layer.11.attention.self.value.weight True\n","bert.encoder.layer.11.attention.self.value.bias True\n","bert.encoder.layer.11.attention.output.dense.weight True\n","bert.encoder.layer.11.attention.output.dense.bias True\n","bert.encoder.layer.11.attention.output.LayerNorm.weight True\n","bert.encoder.layer.11.attention.output.LayerNorm.bias True\n","bert.encoder.layer.11.intermediate.dense.weight True\n","bert.encoder.layer.11.intermediate.dense.bias True\n","bert.encoder.layer.11.output.dense.weight True\n","bert.encoder.layer.11.output.dense.bias True\n","bert.encoder.layer.11.output.LayerNorm.weight True\n","bert.encoder.layer.11.output.LayerNorm.bias True\n","classifier.weight True\n","classifier.bias True\n"]}]},{"cell_type":"code","source":["def tokenize_and_align_labels(examples):\n","    tokenized_inputs = tokenizer(\n","        examples[\"tokens\"],\n","        truncation=True,\n","        max_length=512,\n","        is_split_into_words=True\n","    )\n","\n","    labels = []\n","    for i, label in enumerate(examples[\"ner_tags\"]):\n","        word_ids = tokenized_inputs.word_ids(batch_index=i)\n","        previous_word_idx = None\n","        label_ids = []\n","        for word_idx in word_ids:\n","            if word_idx is None:\n","                label_ids.append(-100)\n","            elif word_idx != previous_word_idx:\n","                label_ids.append(label[word_idx])\n","            else:\n","                # for subword tokens: keep same label if not O, else O\n","                label_ids.append(label[word_idx] if label[word_idx] != label2id[\"O\"] else label2id[\"O\"])\n","            previous_word_idx = word_idx\n","        labels.append(label_ids)\n","\n","    tokenized_inputs[\"labels\"] = labels\n","    return tokenized_inputs\n","\n","tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["e32cd478b72446b791a41d06c09a2105","0ff6b890d78c41c08d231e210fbeaa15","134ed6c96ebb4bbc9deac279faa4991f","a52387b1d2114d45a0aec890df26cde0","812c7ca0c67b46a7a0484cb75bf70774","d926ebbd216a473698060b5f6a91ea86","ad54e7d4b18e4f938322c13dd3e0d350","e29b30e3cf9946c683ee961db859a731","5844e0a0f666485584ad3cb99ad6e8a6","ec1d9d9d3e8c4df4afbac41323f787fa","615103d1e3fc4be6bbb2ce8697e82a40","3904858982a94fe798dd720c2e9e0a20","42686ecab825463dae04139c108064cd","9484713ca5ec476d9d0d05374bc1bafb","4f74d851b3a64f0d83f0205fc1eb2239","52b1f441384d45ec92148d590ca7cf03","c6ff5b88318e4a6190b0cac538716429","4fcd9045e2fe4ce79006bf67df7612a2","630702ae8d01462086249350ddc7e91e","d5e4ec0c3eaa4fa3b82cc2afcd579cf1","13dece3ca1c945d3be9ad4ebd83e2ed8","0ae469b66a8842b68b549ba2d0d103d4","2ae989c82ddb4bb4b2638c423500e33d","09a33a8ccb984c71ae85160d29cfa810","0b9d3f4782704df0815b8643cd35114a","27769f6985784f99a2c87b15d9530c19","7eef2d8251674f3e9552d4924551e83d","6741dcdb0b284034a75a703378153f7e","8b72d170983b4caebce92ba8fa55479a","20bc7f3dd77e41cb81c736d508847b74","ba8db41ca41b407186229efc07b55f45","c484130ea31849da9dcabebe9a66e9a0","7dd3eca76a984e009ef9bf64b107d343"]},"id":"B0U37qKQbgHS","executionInfo":{"status":"ok","timestamp":1759512863573,"user_tz":240,"elapsed":23729,"user":{"displayName":"Sugi g","userId":"15669796817362053311"}},"outputId":"6013cb83-45d1-450a-b75b-9cd5793a585a"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/15661 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e32cd478b72446b791a41d06c09a2105"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1382 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3904858982a94fe798dd720c2e9e0a20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1382 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ae989c82ddb4bb4b2638c423500e33d"}},"metadata":{}}]},{"cell_type":"code","source":["# Normalized weights tensor\n","weights = torch.tensor([0.0519, 0.4344, 0.0951, 1.0000, 0.0045]).to(\"cuda\")\n","\n","# Overwrite model's forward via Trainer\n","def compute_loss(model, inputs, return_outputs=False):\n","    labels = inputs.pop(\"labels\")\n","    outputs = model(**inputs)\n","    logits = outputs.logits\n","    loss_fct = nn.CrossEntropyLoss(weight=weights, ignore_index=-100)\n","    loss = loss_fct(logits.view(-1, logits.shape[-1]), labels.view(-1))\n","    return (loss, outputs) if return_outputs else loss\n"],"metadata":{"id":"7IWk-dXLbmFL","executionInfo":{"status":"ok","timestamp":1759512888094,"user_tz":240,"elapsed":669,"user":{"displayName":"Sugi g","userId":"15669796817362053311"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["data_collator = DataCollatorForTokenClassification(tokenizer)\n"],"metadata":{"id":"qThCYyj-brnN","executionInfo":{"status":"ok","timestamp":1759512890115,"user_tz":240,"elapsed":20,"user":{"displayName":"Sugi g","userId":"15669796817362053311"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["from seqeval.metrics import classification_report\n","import numpy as np\n","\n","def compute_metrics(p):\n","    predictions, labels = p\n","    predictions = np.argmax(predictions, axis=2)\n","\n","    true_labels = [[id2label[l] for l in label if l != -100] for label in labels]\n","    true_preds = [\n","        [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","\n","    report = classification_report(true_labels, true_preds, output_dict=True)\n","    return {\n","        \"precision\": report[\"micro avg\"][\"precision\"],\n","        \"recall\": report[\"micro avg\"][\"recall\"],\n","        \"f1\": report[\"micro avg\"][\"f1-score\"]\n","    }"],"metadata":{"id":"FPYe6O28bs5D","executionInfo":{"status":"ok","timestamp":1759512891762,"user_tz":240,"elapsed":21,"user":{"displayName":"Sugi g","userId":"15669796817362053311"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir=\"./ner_biobert\",\n","    eval_strategy=\"steps\",\n","    eval_steps=500,\n","    save_steps=1000,\n","    logging_steps=100,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=5,\n","    learning_rate=5e-5,\n","    weight_decay=0.01,\n","    save_total_limit=2,\n","    logging_dir=\"./logs\",\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"f1\",\n","    greater_is_better=True,\n","    report_to=[],\n","    push_to_hub=False\n",")\n"],"metadata":{"id":"CXdQWWy3bvcj","executionInfo":{"status":"ok","timestamp":1759512894228,"user_tz":240,"elapsed":68,"user":{"displayName":"Sugi g","userId":"15669796817362053311"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["from transformers import Trainer\n","\n","class WeightedTrainer(Trainer):\n","    def __init__(self, weights, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.weights = weights.to(self.model.device)\n","\n","    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n","        labels = inputs.pop(\"labels\")\n","        outputs = model(**inputs)\n","        logits = outputs.logits\n","        loss_fct = nn.CrossEntropyLoss(weight=self.weights, ignore_index=-100)\n","        loss = loss_fct(logits.view(-1, logits.shape[-1]), labels.view(-1))\n","        return (loss, outputs) if return_outputs else loss\n","\n"],"metadata":{"id":"TEoHbqCTcI25","executionInfo":{"status":"ok","timestamp":1759512896400,"user_tz":240,"elapsed":6,"user":{"displayName":"Sugi g","userId":"15669796817362053311"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["trainer = WeightedTrainer(\n","    weights=weights,\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2sWuGN3McNIp","executionInfo":{"status":"ok","timestamp":1759512899999,"user_tz":240,"elapsed":129,"user":{"displayName":"Sugi g","userId":"15669796817362053311"}},"outputId":"b300a09b-0e60-441f-da79-076ceabda570"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1199848177.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n","  super().__init__(*args, **kwargs)\n"]}]},{"cell_type":"code","source":["trainer.train()\n","\n","metrics = trainer.evaluate(tokenized_datasets[\"test\"])\n","print(metrics)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":415},"id":"pGRbgj2hcVAj","executionInfo":{"status":"ok","timestamp":1759517277223,"user_tz":240,"elapsed":4368015,"user":{"displayName":"Sugi g","userId":"15669796817362053311"}},"outputId":"21ccd67e-58c2-42e0-da1e-1bc448c17f09","collapsed":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4895' max='4895' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4895/4895 1:12:01, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.065200</td>\n","      <td>0.028726</td>\n","      <td>0.754336</td>\n","      <td>0.989322</td>\n","      <td>0.855995</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.032700</td>\n","      <td>0.015939</td>\n","      <td>0.863754</td>\n","      <td>0.995225</td>\n","      <td>0.924841</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.014300</td>\n","      <td>0.011493</td>\n","      <td>0.919909</td>\n","      <td>0.995623</td>\n","      <td>0.956270</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.011400</td>\n","      <td>0.011373</td>\n","      <td>0.898931</td>\n","      <td>0.998077</td>\n","      <td>0.945913</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.007200</td>\n","      <td>0.009939</td>\n","      <td>0.926613</td>\n","      <td>0.997347</td>\n","      <td>0.960680</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.018200</td>\n","      <td>0.009903</td>\n","      <td>0.954753</td>\n","      <td>0.997811</td>\n","      <td>0.975807</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.006300</td>\n","      <td>0.007644</td>\n","      <td>0.948122</td>\n","      <td>0.997546</td>\n","      <td>0.972206</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.004500</td>\n","      <td>0.009916</td>\n","      <td>0.961541</td>\n","      <td>0.998209</td>\n","      <td>0.979532</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.005300</td>\n","      <td>0.008835</td>\n","      <td>0.964618</td>\n","      <td>0.998077</td>\n","      <td>0.981062</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='87' max='87' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [87/87 00:40]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 0.0056439051404595375, 'eval_precision': 0.9626585101637672, 'eval_recall': 0.9974909210960713, 'eval_f1': 0.9797652247227446, 'eval_runtime': 43.0514, 'eval_samples_per_second': 32.101, 'eval_steps_per_second': 2.021, 'epoch': 5.0}\n"]}]},{"cell_type":"code","source":["save_path = \"biobert-ner-final\"\n","\n","# Save model\n","model.save_pretrained(save_path)\n","\n","# Save tokenizer\n","tokenizer.save_pretrained(save_path)\n","\n","print(f\"✅ Model and tokenizer saved to '{save_path}'\")\n"],"metadata":{"id":"jK_6-rNtyTK9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759517428919,"user_tz":240,"elapsed":43152,"user":{"displayName":"Sugi g","userId":"15669796817362053311"}},"outputId":"8406a6be-db2f-4220-aba6-d089046c8ccf"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Model and tokenizer saved to 'biobert-ner-final'\n"]}]},{"cell_type":"code","source":["from seqeval.metrics import classification_report\n","\n","preds_output = trainer.predict(tokenized_datasets[\"validation\"])\n","preds = np.argmax(preds_output.predictions, axis=2)\n","\n","true_labels = [[id2label[l] for l in label if l != -100] for label in preds_output.label_ids]\n","true_preds = [\n","    [id2label[p] for (p, l) in zip(pred, label) if l != -100]\n","    for pred, label in zip(preds, preds_output.label_ids)\n","]\n","\n","print(classification_report(true_labels, true_preds, digits=3))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"id":"2zRYasGNunVA","executionInfo":{"status":"ok","timestamp":1759517378349,"user_tz":240,"elapsed":48024,"user":{"displayName":"Sugi g","userId":"15669796817362053311"}},"outputId":"d2022f4e-e3b3-4565-d8b7-1e1720597c69"},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","         ADE      0.961     0.998     0.979     10221\n","        DRUG      0.962     0.999     0.980      4857\n","\n","   micro avg      0.962     0.998     0.980     15078\n","   macro avg      0.962     0.998     0.980     15078\n","weighted avg      0.962     0.998     0.980     15078\n","\n"]}]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForTokenClassification\n","import torch\n","import re\n","\n","# -----------------------------\n","# 1️⃣ Load model & tokenizer\n","# -----------------------------\n","model_path = \"biobert-ner-final\"\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","model = AutoModelForTokenClassification.from_pretrained(model_path)\n","model.eval()\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model.to(device)\n","\n","# -----------------------------\n","# 2️⃣ Input sentence\n","# -----------------------------\n","sentence = \"moderna shot was administered and got fever, headache\"\n","\n","# Split into words/punctuation\n","tokens = re.findall(r\"\\w+|[^\\w\\s]\", sentence)\n","\n","# -----------------------------\n","# 3️⃣ Tokenize\n","# -----------------------------\n","encoded = tokenizer(\n","    tokens,\n","    is_split_into_words=True,\n","    truncation=True,\n","    max_length=512,\n","    return_tensors=\"pt\"\n",").to(device)\n","\n","# -----------------------------\n","# 4️⃣ Predict\n","# -----------------------------\n","with torch.no_grad():\n","    outputs = model(**encoded)\n","    predictions = torch.argmax(outputs.logits, dim=-1)[0].cpu().numpy()\n","\n","# -----------------------------\n","# 5️⃣ Align predictions to words\n","# -----------------------------\n","word_ids = encoded.word_ids(batch_index=0)\n","\n","label_list = [\"B-ADE\",\"B-DRUG\", \"I-ADE\",  \"I-DRUG\", \"O\"]\n","id2label = {i: l for i, l in enumerate(label_list)}\n","\n","pred_labels = []\n","previous_word_idx = None\n","for idx, word_idx in enumerate(word_ids):\n","    if word_idx is None or word_idx == previous_word_idx:\n","        continue\n","    pred_labels.append((tokens[word_idx], id2label[predictions[idx]]))\n","    previous_word_idx = word_idx\n","\n","print(\"🔹 Token-level predictions:\")\n","print(pred_labels)\n","\n","import string\n","\n","entities = {\"DRUG\": [], \"ADE\": []}\n","current_entity = None\n","current_words = []\n","\n","for word, label in pred_labels:\n","    # Skip punctuation-only tokens\n","    if all(ch in string.punctuation for ch in word):\n","        continue\n","\n","    if label.startswith(\"B-\"):\n","        if current_entity and current_words:\n","            entities[current_entity].append(\" \".join(current_words))\n","        current_entity = label.split(\"-\")[1]\n","        current_words = [word]\n","\n","    elif label.startswith(\"I-\") and current_entity == label.split(\"-\")[1]:\n","        current_words.append(word)\n","\n","    elif label.startswith(\"B-\") and current_entity == label.split(\"-\")[1]:\n","        # Handle consecutive B-XXX (merge case)\n","        current_words.append(word)\n","\n","    else:\n","        if current_entity and current_words:\n","            entities[current_entity].append(\" \".join(current_words))\n","        current_entity = None\n","        current_words = []\n","\n","# Add last\n","if current_entity and current_words:\n","    entities[current_entity].append(\" \".join(current_words))\n","\n","print(\"\\n🔹 Entity-level predictions:\")\n","for ent_type, ent_list in entities.items():\n","    print(f\"{ent_type}: {', '.join(ent_list) if ent_list else 'None'}\")"],"metadata":{"id":"ZKFLLrL_yd3R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759517505436,"user_tz":240,"elapsed":466,"user":{"displayName":"Sugi g","userId":"15669796817362053311"}},"outputId":"793e904d-5a4a-47c1-f640-0f94b1a7e3c6"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["🔹 Token-level predictions:\n","[('moderna', 'B-DRUG'), ('shot', 'O'), ('was', 'O'), ('administered', 'O'), ('and', 'O'), ('got', 'O'), ('fever', 'B-ADE'), (',', 'O'), ('headache', 'B-ADE')]\n","\n","🔹 Entity-level predictions:\n","DRUG: moderna\n","ADE: fever, headache\n"]}]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForTokenClassification\n","import torch\n","import re\n","\n","# -----------------------------\n","# 1️⃣ Load model & tokenizer\n","# -----------------------------\n","model_path = \"biobert-ner-final\"\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","model = AutoModelForTokenClassification.from_pretrained(model_path)\n","model.eval()\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model.to(device)\n","\n","# -----------------------------\n","# 2️⃣ Post-processing dictionary\n","# -----------------------------\n","POSTPROCESS_DICT = {\n","    \"DRUG\": {\n","        \"pfizer\", \"moderna\", \"astrazeneca\", \"covaxin\",\n","        \"janssen\", \"johnson\", \"johnson and johnson\", \"biontech\"\n","    },\n","    \"ADE\": {\n","        \"fever\", \"headache\", \"dizziness\", \"nausea\",\n","        \"rash\", \"fatigue\", \"chills\", \"itching\", \"sweating\",\n","        \"chest pain\"\n","    }\n","}\n","\n","def normalize(text):\n","    \"\"\"Lowercase, remove punctuation, collapse spaces.\"\"\"\n","    text = text.lower()\n","    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n","    text = re.sub(r\"\\s+\", \" \", text).strip()\n","    return text\n","\n","def postprocess_entities(text, entities):\n","    \"\"\"Dictionary-based fuzzy mapping.\"\"\"\n","    new_entities = {\"DRUG\": list(entities[\"DRUG\"]), \"ADE\": list(entities[\"ADE\"])}\n","    text_norm = normalize(text)\n","\n","    for ent_type, vocab in POSTPROCESS_DICT.items():\n","        for word in vocab:\n","            word_norm = normalize(word)\n","            if word_norm in text_norm and not any(word_norm in normalize(e) for e in new_entities[ent_type]):\n","                new_entities[ent_type].append(word)\n","    return new_entities\n","\n","def clean_entities(entities):\n","    \"\"\"DRUG/ADE cleanup for unrealistic spans.\"\"\"\n","    cleaned = {\"DRUG\": [], \"ADE\": []}\n","\n","    # Clean ADE\n","    for ade in entities.get(\"ADE\", []):\n","        ade = ade.strip(\"., \")\n","        if ade and ade.lower() not in [\"and\", \"reported\", \"later\", \"severe\"]:\n","            cleaned[\"ADE\"].append(ade)\n","\n","    # Clean DRUG\n","    for drug in entities.get(\"DRUG\", []):\n","        drug = re.sub(r\"\\band\\b.*\", \"\", drug)\n","        drug = drug.strip(\"., \")\n","        if re.search(r\"[A-Z]\", drug) and len(drug.split()) <= 5:\n","            cleaned[\"DRUG\"].append(drug)\n","\n","    return cleaned\n","\n","# -----------------------------\n","# 3️⃣ Predict function\n","# -----------------------------\n","def predict_entities(sentences):\n","    id2label = {0:\"B-ADE\", 1:\"B-DRUG\", 2:\"I-ADE\", 3:\"I-DRUG\", 4:\"O\"}\n","\n","    for sent in sentences:\n","        print(\"\\n==============================\")\n","        print(\"Sentence:\", sent)\n","\n","        # Tokenize\n","        tokens = re.findall(r\"\\w+|[^\\w\\s]\", sent)\n","        encoded = tokenizer(\n","            tokens,\n","            is_split_into_words=True,\n","            truncation=True,\n","            max_length=512,\n","            return_tensors=None\n","        )\n","        inputs = {k: torch.tensor([v]).to(device) for k, v in encoded.items()}\n","\n","        # Predict\n","        with torch.no_grad():\n","            outputs = model(**inputs)\n","            predictions = torch.argmax(outputs.logits, dim=-1)[0].cpu().numpy()\n","\n","        # Align tokens with predictions\n","        word_ids = encoded.word_ids(batch_index=0)\n","        pred_labels = []\n","        prev_word_idx = None\n","        for idx, word_idx in enumerate(word_ids):\n","            if word_idx is None or word_idx == prev_word_idx:\n","                continue\n","            pred_labels.append((tokens[word_idx], predictions[idx]))\n","            prev_word_idx = word_idx\n","\n","        pred_labels_named = [(word, id2label[label]) for word, label in pred_labels]\n","        print(\"🔹 Token-level predictions:\")\n","        print(pred_labels_named)\n","\n","        # Merge contiguous entities\n","        entities = {\"DRUG\": [], \"ADE\": []}\n","        current_entity = None\n","        current_words = []\n","\n","        for word, label in pred_labels_named:\n","            if label in [\"B-DRUG\", \"I-DRUG\"]:\n","                if current_entity == \"DRUG\":\n","                    current_words.append(word)\n","                else:\n","                    if current_entity and current_words:\n","                        entities[current_entity].append(\" \".join(current_words))\n","                    current_entity = \"DRUG\"\n","                    current_words = [word]\n","            elif label in [\"B-ADE\", \"I-ADE\"]:\n","                if current_entity == \"ADE\":\n","                    current_words.append(word)\n","                else:\n","                    if current_entity and current_words:\n","                        entities[current_entity].append(\" \".join(current_words))\n","                    current_entity = \"ADE\"\n","                    current_words = [word]\n","            else:\n","                if current_entity and current_words:\n","                    entities[current_entity].append(\" \".join(current_words))\n","                current_entity = None\n","                current_words = []\n","\n","        if current_entity and current_words:\n","            entities[current_entity].append(\" \".join(current_words))\n","\n","        print(\"\\n🔹 Entity-level predictions (raw model):\")\n","        for ent_type, ent_list in entities.items():\n","            print(f\"{ent_type}: {', '.join(ent_list) if ent_list else 'None'}\")\n","\n","        # Post-process\n","        entities_clean = clean_entities(entities)\n","        entities_post = postprocess_entities(sent, entities_clean)\n","\n","        print(\"\\n🔹 Entity-level predictions (post-processed, fuzzy match):\")\n","        for ent_type, ent_list in entities_post.items():\n","            print(f\"{ent_type}: {', '.join(ent_list) if ent_list else 'None'}\")\n","\n","\n","# -----------------------------\n","# 4️⃣ Example usage\n","# -----------------------------\n","sentences = [\n","    \"After taking AstraZeneca vaccine, the patient experienced nausea and chest pain.\",\n","    \"He was given Covaxin but developed rash and severe itching.\",\n","    \"The subject reported fatigue, dizziness, and fever following the Pfizer booster.\",\n","    \"Moderna shot was administered without immediate side effects.\",\n","    \"Patient got Pfizer-BioNTech vaccine and later reported severe dizziness, fatigue, and rash.\"\n","]\n","\n","predict_entities(sentences)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QREJVD1B1hKX","executionInfo":{"status":"ok","timestamp":1759517510454,"user_tz":240,"elapsed":293,"user":{"displayName":"Sugi g","userId":"15669796817362053311"}},"outputId":"1a48702f-04c2-4a9f-edf5-c8014839719f"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==============================\n","Sentence: After taking AstraZeneca vaccine, the patient experienced nausea and chest pain.\n","🔹 Token-level predictions:\n","[('After', 'O'), ('taking', 'O'), ('AstraZeneca', 'O'), ('vaccine', 'O'), (',', 'O'), ('the', 'O'), ('patient', 'O'), ('experienced', 'O'), ('nausea', 'B-ADE'), ('and', 'O'), ('chest', 'B-ADE'), ('pain', 'I-ADE'), ('.', 'I-ADE')]\n","\n","🔹 Entity-level predictions (raw model):\n","DRUG: None\n","ADE: nausea, chest pain .\n","\n","🔹 Entity-level predictions (post-processed, fuzzy match):\n","DRUG: astrazeneca\n","ADE: nausea, chest pain\n","\n","==============================\n","Sentence: He was given Covaxin but developed rash and severe itching.\n","🔹 Token-level predictions:\n","[('He', 'O'), ('was', 'O'), ('given', 'O'), ('Covaxin', 'B-DRUG'), ('but', 'O'), ('developed', 'O'), ('rash', 'B-ADE'), ('and', 'O'), ('severe', 'O'), ('itching', 'O'), ('.', 'O')]\n","\n","🔹 Entity-level predictions (raw model):\n","DRUG: Covaxin\n","ADE: rash\n","\n","🔹 Entity-level predictions (post-processed, fuzzy match):\n","DRUG: Covaxin\n","ADE: rash, itching\n","\n","==============================\n","Sentence: The subject reported fatigue, dizziness, and fever following the Pfizer booster.\n","🔹 Token-level predictions:\n","[('The', 'O'), ('subject', 'O'), ('reported', 'O'), ('fatigue', 'B-ADE'), (',', 'O'), ('dizziness', 'B-ADE'), (',', 'O'), ('and', 'O'), ('fever', 'B-ADE'), ('following', 'O'), ('the', 'O'), ('Pfizer', 'B-DRUG'), ('booster', 'B-DRUG'), ('.', 'B-DRUG')]\n","\n","🔹 Entity-level predictions (raw model):\n","DRUG: Pfizer booster .\n","ADE: fatigue, dizziness, fever\n","\n","🔹 Entity-level predictions (post-processed, fuzzy match):\n","DRUG: Pfizer booster\n","ADE: fatigue, dizziness, fever\n","\n","==============================\n","Sentence: Moderna shot was administered without immediate side effects.\n","🔹 Token-level predictions:\n","[('Moderna', 'B-DRUG'), ('shot', 'O'), ('was', 'O'), ('administered', 'O'), ('without', 'O'), ('immediate', 'O'), ('side', 'O'), ('effects', 'O'), ('.', 'O')]\n","\n","🔹 Entity-level predictions (raw model):\n","DRUG: Moderna\n","ADE: None\n","\n","🔹 Entity-level predictions (post-processed, fuzzy match):\n","DRUG: Moderna\n","ADE: None\n","\n","==============================\n","Sentence: Patient got Pfizer-BioNTech vaccine and later reported severe dizziness, fatigue, and rash.\n","🔹 Token-level predictions:\n","[('Patient', 'O'), ('got', 'O'), ('Pfizer', 'B-DRUG'), ('-', 'B-DRUG'), ('BioNTech', 'B-DRUG'), ('vaccine', 'O'), ('and', 'O'), ('later', 'O'), ('reported', 'O'), ('severe', 'O'), ('dizziness', 'B-ADE'), (',', 'O'), ('fatigue', 'B-ADE'), (',', 'O'), ('and', 'O'), ('rash', 'B-ADE'), ('.', 'B-ADE')]\n","\n","🔹 Entity-level predictions (raw model):\n","DRUG: Pfizer - BioNTech\n","ADE: dizziness, fatigue, rash .\n","\n","🔹 Entity-level predictions (post-processed, fuzzy match):\n","DRUG: Pfizer - BioNTech\n","ADE: dizziness, fatigue, rash\n"]}]},{"cell_type":"code","source":["# Zip the last checkpoint folder\n","!zip -r checkpoint-4895.zip /content/ner_biobert/checkpoint-4895\n","\n","# Download the zip\n","from google.colab import files\n","files.download(\"checkpoint-4895.zip\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":225},"id":"l_r-EadhUi3A","executionInfo":{"status":"ok","timestamp":1759517575880,"user_tz":240,"elapsed":36386,"user":{"displayName":"Sugi g","userId":"15669796817362053311"}},"outputId":"00415f38-421b-4d21-86ed-dfb66e224afe"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/ner_biobert/checkpoint-4895/ (stored 0%)\n","  adding: content/ner_biobert/checkpoint-4895/optimizer.pt (deflated 8%)\n","  adding: content/ner_biobert/checkpoint-4895/tokenizer.json (deflated 70%)\n","  adding: content/ner_biobert/checkpoint-4895/model.safetensors (deflated 7%)\n","  adding: content/ner_biobert/checkpoint-4895/config.json (deflated 51%)\n","  adding: content/ner_biobert/checkpoint-4895/rng_state.pth (deflated 26%)\n","  adding: content/ner_biobert/checkpoint-4895/tokenizer_config.json (deflated 74%)\n","  adding: content/ner_biobert/checkpoint-4895/special_tokens_map.json (deflated 42%)\n","  adding: content/ner_biobert/checkpoint-4895/training_args.bin (deflated 53%)\n","  adding: content/ner_biobert/checkpoint-4895/trainer_state.json (deflated 76%)\n","  adding: content/ner_biobert/checkpoint-4895/scheduler.pt (deflated 62%)\n","  adding: content/ner_biobert/checkpoint-4895/vocab.txt (deflated 49%)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_be90bd5e-8bb3-4aa7-bd9d-9e758b250ebb\", \"checkpoint-4895.zip\", 607429391)"]},"metadata":{}}]},{"cell_type":"code","source":["\n","# Zip the last checkpoint folder\n","!zip -r biobert-ner-final.zip /content/biobert-ner-final\n","\n","# Download the zip\n","from google.colab import files\n","files.download(\"biobert-ner-final.zip\")\n"],"metadata":{"id":"Wbczpx0Y0jky","colab":{"base_uri":"https://localhost:8080/","height":138},"executionInfo":{"status":"ok","timestamp":1759517664682,"user_tz":240,"elapsed":24828,"user":{"displayName":"Sugi g","userId":"15669796817362053311"}},"outputId":"586940ec-c7db-49b6-d825-6c8c18b63ace"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/biobert-ner-final/ (stored 0%)\n","  adding: content/biobert-ner-final/tokenizer.json (deflated 70%)\n","  adding: content/biobert-ner-final/model.safetensors (deflated 7%)\n","  adding: content/biobert-ner-final/config.json (deflated 51%)\n","  adding: content/biobert-ner-final/tokenizer_config.json (deflated 74%)\n","  adding: content/biobert-ner-final/special_tokens_map.json (deflated 42%)\n","  adding: content/biobert-ner-final/vocab.txt (deflated 49%)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_baf0c1f6-92de-4c2d-a3a6-11222d3e6168\", \"biobert-ner-final.zip\", 399345420)"]},"metadata":{}}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"i5uyhXCo1ta1"},"execution_count":null,"outputs":[]}]}