### **BIOBERT NER Model Training**

| **Step** | **Component**                     | **Summary**                                                                                                                                                                       |
| -------- | --------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1Ô∏è‚É£      | **Gold Data Creation**            | Manually annotated ADE and DRUG entities from clinical narratives to build a high-quality labeled dataset using Label Studio.                                                                        |
| 2Ô∏è‚É£      | **Weak Supervision Augmentation** | Integrated additional weakly labeled data to expand training coverage.                                                                      |
| 3Ô∏è‚É£      | **Class Weight Balancing**        | Computed **class weights** to counter label imbalance ‚Äî ensuring the model learns equally across frequent and rare entity types.                                                  |
| 4Ô∏è‚É£      | **Layer Freezing Strategy (Transfer Learning)**       | Used **progressive fine-tuning**: froze lower layers of BioBERT and **unfroze last 4 encoder layers** + classifier head to retain domain knowledge while adapting to ADE context. |
| 5Ô∏è‚É£ | **Training & Validation** |  Fine-tuned BioBERT on gold + weak data with weighted loss and token-level evaluation (precision, recall, F1).|
| 6Ô∏è‚É£   | **Post-Processing Dictionary**    | Added domain dictionary for normalization and missed-entity recovery after model inference, ensuring coverage for known ADE/Drug names.                                           |

‚úÖ In short:
This pipeline combines weak supervision, class balancing, and selective fine-tuning to adapt BioBERT efficiently for clinical NER, while dictionary-based post-processing ensures robust entity coverage.


### **Severity Classifier Training (Snorkel Weak Supervision)**

| **Step** | **Component**                  | **Summary**                                                                                                                                                                                                          |
| -------- | ------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1Ô∏è‚É£      | **Input Data**                 | Used unstructured symptom_text and structured fields from VAERS dataset as input.                                                                                                                            |
| 2Ô∏è‚É£      | **Labeling Functions (LFs)**   | Defined **rule-based labeling functions** on structured fields (`DIED`, `HOSPITAL`, `L_THREAT`, `DISABLE`) and unstructured text (`SYMPTOM_TEXT`). Each LF votes for a class: **Severe**, **Moderate**, or **Mild**. |
| 3Ô∏è‚É£      | **Weak Label Generation**      | Combined multiple LF outputs using **Snorkel‚Äôs LabelModel**, which estimates LF accuracies and correlations to produce **probabilistic weak labels**.                                                                |
| 4Ô∏è‚É£      | **Label Aggregation**          | Converted Snorkel probabilities into **final weak labels** (`weak_label_id`, `weak_label`) and appended them to the dataset.                                                                                         |
| 5Ô∏è‚É£      | **Training Data Creation**     | Produced a unified dataset with **entity spans + weak severity labels** for training the downstream **severity classifier**.                                            |
| 6Ô∏è‚É£      | **Integration for Classifier** | These weak labels served as **pseudo-gold labels** to train a **BioBERT-based severity classifier**, reducing manual annotation effort.                                                                              |

‚úÖ **In short:**
Snorkel was used to automatically infer **severity levels** (Severe, Moderate, Mild) from mixed structured + unstructured data, creating **weakly supervised training data** for the classifier ‚Äî a scalable alternative to manual labeling.


## **Named Entity Recognition (NER)**

| **Step** | **Task**                    | **Purpose / Outcome**                                              |
| :------: | --------------------------- | ------------------------------------------------------------------ |
|    1Ô∏è‚É£     | **Input Loading**           | Upload CSV containing symptom text and age                         |
|     2Ô∏è‚É£   | **Age Grouping**            | Categorize patients into Child / Young Adult / Middle Age / Senior |
|     3Ô∏è‚É£    | **Load BioBERT NER Model**  | Initialize token classification model for ADE & Drug detection     |
|     4Ô∏è‚É£   | **Tokenization & Labeling** | Predict BIO tags for each token (B/I-ADE, B/I-DRUG, O)             |
|     5Ô∏è‚É£   | **Entity Assembly**         | Merge sub-tokens to form full ADE or Drug phrases                  |
|     6Ô∏è‚É£    | **Visualization**           | Highlight detected entities (red = ADE, blue = Drug)               |
|    7Ô∏è‚É£   | **Post Processing**         | Rule-based dictionary matching and text cleaning to recover missed ADE/Drug entities and refine NER output quality|



üü© *Outcome:* Extracts clean ADE and Drug entities for downstream analysis.

---

## **Severity Classification + Explainability**

| **Step** | **Task**                | **Purpose / Outcome**                                          |
| :------: | ----------------------- | -------------------------------------------------------------- |
|     1Ô∏è‚É£   | **Input Loading** | Get symptom_text and weak_labels from input data
|2Ô∏è‚É£  | **Load Classifier**     | Load fine-tuned text classification model                      |
|     3Ô∏è‚É£     | **Predict Severity**    | Output severity levels (Severe / Moderate / Mild)              |
|     4Ô∏è‚É£     | **SHAP Explainability** | Identify which words drive the model‚Äôs severity decision       |
|   5Ô∏è‚É£  | **Token Highlights**    | Visualize important symptom words in color-coded text          |
|     6Ô∏è‚É£    | **Feature Importance**  | Show bar chart of word influence scores                        |

üü¶ *Outcome:* Provides both automated severity scoring and transparent, interpretable results.

---

## **Clustering & Visuals**

| **Step** | **Task**                      | **Purpose / Outcome**                                                       |
| :------: | ----------------------------- | --------------------------------------------------------------------------- |
|     1Ô∏è‚É£    | **Sentence Embedding**        | Convert each ADE record into numerical representation (SentenceTransformer) |
|     2Ô∏è‚É£  | **Hybrid Severity** | Combines classifier output & rule-based fallback for determining modifiers for clustering |
| 3Ô∏è‚É£| **Dimensionality Reduction**  | Apply t-SNE for 2D visual mapping of embeddings                             |
|    4Ô∏è‚É£    | **K-Means Clustering**        | Group similar ADE cases based on textual similarity                         |
|     5Ô∏è‚É£    | **Interactive Visualization** | Use Plotly scatter plot for exploration and insight discovery               |

üü® *Outcome:* Reveals hidden relationships between symptoms, drugs, and severity.


### ü©∫ **Clinical Insights Dashboard (Streamlit UI)**

| **Step** | **Component**                   | **Summary**                                                                                                                                                                      |
| -------- | ------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1Ô∏è‚É£      | **Purpose**                     | Provides clinicians with an **interactive dashboard** to explore AI-classified **adverse drug events (ADEs)** across drugs, symptoms, severity levels, and patient demographics. |
| 2Ô∏è‚É£      | **Data Preparation**            | Expanded list columns (`DRUG`, `ADE`) to ensure each ADE‚Äìdrug pair is analyzed individually for accurate aggregation and visualization.                             |
| 3Ô∏è‚É£      | **Filtering**                   | Added **dynamic filters** for **Drug**, **ADE**, and **Cluster** to explore focused subsets of the dataset interactively.                                                        |
| 4Ô∏è‚É£      | **Visualization**               | Displayed multiple **bar charts** showing the **distribution of severity** (`pred_label`) and **age groups**, enabling trend analysis across demographics.                       |
| 5Ô∏è‚É£      | **Clinical Summary Generation** | Computed a grouped **clinical summary table** (`DRUG`, `ADE`, `count`) to summarize frequent ADE‚Äìdrug associations.                                                              |
| 6Ô∏è‚É£      | **Data Export**                 | Enabled **CSV downloads** (Filtered Cases & Clinical Summary) from the sidebar for further medical review and audit.                                                             |

‚úÖ **In short:**
The **Clinical ADE Insights Dashboard** transforms AI model outputs into **actionable clinical intelligence**, allowing doctors and researchers to visually explore severity trends, ADE frequency, and patient demographics ‚Äî bridging the gap between AI predictions and clinical interpretation.





